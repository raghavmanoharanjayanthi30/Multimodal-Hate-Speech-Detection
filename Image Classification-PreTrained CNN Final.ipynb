{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b232ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a656eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20920d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_ids.txt', 'r') as file:\n",
    "    # Read all lines into a list\n",
    "    lines = file.readlines()\n",
    "    test_ids = []\n",
    "\n",
    "    # Print each line\n",
    "    for line in lines:\n",
    "        test_ids.append(line.strip() + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bac303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_ids.txt', 'r') as file:\n",
    "    # Read all lines into a list\n",
    "    lines = file.readlines()\n",
    "    train_ids = []\n",
    "\n",
    "    # Print each line\n",
    "    for line in lines:\n",
    "        train_ids.append(line.strip() + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61a2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_ids.txt', 'r') as file:\n",
    "    # Read all lines into a list\n",
    "    lines = file.readlines()\n",
    "    val_ids = []\n",
    "\n",
    "    # Print each line\n",
    "    for line in lines:\n",
    "        val_ids.append(line.strip() + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29335bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training dataset:  134823\n",
      "Number of images in validation dataset:  5000\n",
      "Number of images in testing dataset:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in training dataset: \", len(train_ids))\n",
    "print(\"Number of images in validation dataset: \", len(val_ids))\n",
    "print(\"Number of images in testing dataset: \", len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ff78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image files\n",
    "def get_image_files(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    image_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        if file.lower().endswith('.jpg'):\n",
    "            image_files.append(file)\n",
    "    \n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d0eb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/train'\n",
    "test_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/test'\n",
    "val_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c080c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(source_path, destination_path, titles):\n",
    "    for title in titles:\n",
    "        source_file = os.path.join(data_directory, title)\n",
    "        destination_file = os.path.join(destination_path, title)\n",
    "        shutil.copy(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b04cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_directory = \"/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/img_resized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490e14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#already done\n",
    "#copy_files(data_directory, train_path, train_ids)\n",
    "#copy_files(data_directory, val_path, val_ids)\n",
    "#copy_files(data_directory, test_path, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f78605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_image_files(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cdba8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project/MMHS150K_GT.json'\n",
    "\n",
    "# Open the JSON file for reading\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f737fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.reset_index()\n",
    "newColumns = {\"index\": \"id\"}\n",
    "df = df.rename(columns=newColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5855206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 for nothate, #1 for hate\n",
    "def labels_to_binary(labels):\n",
    "    if sum(labels) <= 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c289aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61547"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Hate(1)_vs_NotHate(0)\"] = df[\"labels\"].apply(labels_to_binary)\n",
    "sum(df[\"Hate(1)_vs_NotHate(0)\"]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4d239c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nothate_ids = df[df[\"Hate(1)_vs_NotHate(0)\"]==0][\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9961e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_ids = df[df[\"Hate(1)_vs_NotHate(0)\"]==1][\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b65bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nothate_ids = [x + '.jpg' for x in nothate_ids]\n",
    "hate_ids = [x + '.jpg' for x in hate_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac087cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hate_train_ids = []\n",
    "hate_val_ids = []\n",
    "hate_test_ids = []\n",
    "for id_ in hate_ids:\n",
    "    if id_ in train_ids:\n",
    "        hate_train_ids.append(id_)\n",
    "    elif id_ in test_ids:\n",
    "        hate_test_ids.append(id_)\n",
    "    else:\n",
    "        hate_val_ids.append(id_)\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c42416cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"nothate_train_ids = []\n",
    "nothate_val_ids = []\n",
    "nothate_test_ids = []\n",
    "for id_ in nothate_ids:\n",
    "    if id_ in train_ids:\n",
    "        nothate_train_ids.append(id_)\n",
    "    elif id_ in test_ids:\n",
    "        nothate_test_ids.append(id_)\n",
    "    else:\n",
    "        nothate_val_ids.append(id_)\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "598f1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "#from keras.applications import ResNet50\n",
    "#from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "import cv2\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = '/Users/raghavraahul/Downloads/Machine Learning under a Modern Optimization Lens/ML Project'\n",
    "\n",
    "# Define the image size based on the pre-trained model's requirements\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def preprocess_with_denoising(image):\n",
    "    # Gaussian Blur for noise reduction\n",
    "    denoised_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Original preprocess_input function\n",
    "    preprocessed_image = preprocess_input(denoised_image)\n",
    "\n",
    "    return preprocessed_image\n",
    "\n",
    "# ImageDataGenerator with noise reduction in preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_with_denoising,\n",
    "    rescale=1./255,  # Rescale pixel values to [0, 1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2db29051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58954 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators for training, validation, and test sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path, 'train'),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # Set to 'binary' for binary classification\n",
    "    shuffle=False  # set shuffle to False for feature extraction\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path, 'valid'),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path, 'test'),\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24d90e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Local path to save the weights file\n",
    "local_weights_path = '/Users/raghavraahul/Downloads/'\n",
    "\n",
    "# Download and save the weights of the entire VGG16 model\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg16_model.save_weights(local_weights_path + 'vgg16_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e63a2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "\n",
    "# Create the model with the correct architecture\n",
    "base_model = VGG16(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Modify the number of filters in the first convolutional layer\n",
    "\n",
    "#This modification assumes that the original weights file had 64 filters, \n",
    "#and you're adjusting it to match the current model with 32 filters. \n",
    "#base_model.layers[1].set_weights([base_model.layers[1].get_weights()[0][:, :, :, :32]])\n",
    "\n",
    "# Load the modified weights\n",
    "base_model.load_weights(local_weights_path + 'vgg16_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04750c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 26250s 14s/step\n",
      "157/157 [==============================] - 2272s 14s/step\n",
      "313/313 [==============================] - 8361s 27s/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features from images using the pre-trained model\n",
    "train_features = base_model.predict(train_generator, steps=len(train_generator))\n",
    "validation_features = base_model.predict(validation_generator, steps=len(validation_generator))\n",
    "test_features = base_model.predict(test_generator, steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bd8c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the features\n",
    "train_features = np.reshape(train_features, (len(train_generator.classes), -1))\n",
    "validation_features = np.reshape(validation_features, (len(validation_generator.classes), -1))\n",
    "test_features = np.reshape(test_features, (len(test_generator.classes), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00cabdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('VGG16_features.npz', train=train_features, validation=validation_features, test=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e8b5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load the extracted features\n",
    "\n",
    "loaded_arrays = np.load('VGG16_features.npz')\n",
    "\n",
    "# Access individual arrays using keys\n",
    "train_features = loaded_arrays['train']\n",
    "validation_features = loaded_arrays['validation']\n",
    "test_features = loaded_arrays['test']\n",
    "\n",
    "#train_features = np.load('imagenet_train_features.npy')\n",
    "#validation_features = np.load('imagenet_validation_features.npy')\n",
    "#test_features = np.load('imagenet_test_features.npy')\n",
    "\n",
    "# Load the corresponding labels\n",
    "train_labels = train_generator.classes\n",
    "validation_labels = validation_generator.classes\n",
    "test_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "298b04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the custom model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=train_features.shape[1])) #input\n",
    "\n",
    "model.add(Dense(128, activation='relu', input_dim=train_features.shape[1]))\n",
    "model.add(Dense(64, activation='relu', input_dim=train_features.shape[1]))\n",
    "model.add(Dense(32, activation='relu', input_dim=train_features.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid')) #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be267580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy', AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e7f8a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1843/1843 [==============================] - 67s 35ms/step - loss: 0.6970 - accuracy: 0.4975 - auc: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_auc: 0.5000\n",
      "Epoch 2/10\n",
      "1843/1843 [==============================] - 62s 34ms/step - loss: 0.6932 - accuracy: 0.5001 - auc: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_auc: 0.5000\n",
      "Epoch 3/10\n",
      "1843/1843 [==============================] - 64s 34ms/step - loss: 0.6932 - accuracy: 0.5005 - auc: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.5000\n",
      "Epoch 4/10\n",
      "1843/1843 [==============================] - 64s 35ms/step - loss: 0.6947 - accuracy: 0.4981 - auc: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_auc: 0.5000\n",
      "Epoch 5/10\n",
      "1843/1843 [==============================] - 67s 36ms/step - loss: 0.6932 - accuracy: 0.4986 - auc: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000 - val_auc: 0.5000\n",
      "Epoch 6/10\n",
      "1843/1843 [==============================] - 64s 35ms/step - loss: 0.6931 - accuracy: 0.5019 - auc: 0.5036 - val_loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.5000\n",
      "Epoch 7/10\n",
      "1843/1843 [==============================] - 68s 37ms/step - loss: 0.6932 - accuracy: 0.4989 - auc: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.5000\n",
      "Epoch 8/10\n",
      "1843/1843 [==============================] - 64s 35ms/step - loss: 0.6932 - accuracy: 0.4996 - auc: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.5000\n",
      "Epoch 9/10\n",
      "1843/1843 [==============================] - 64s 35ms/step - loss: 0.6932 - accuracy: 0.5015 - auc: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.5000\n",
      "Epoch 10/10\n",
      "1843/1843 [==============================] - 69s 38ms/step - loss: 0.6932 - accuracy: 0.5005 - auc: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the extracted features\n",
    "history = model.fit(train_features, train_labels, \n",
    "                    epochs=10, \n",
    "                    batch_size=32,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9cf561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 0.6932 - accuracy: 0.5001 - auc: 0.5000\n",
      "Test accuracy: 50.01%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_features, test_labels)\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f09c9193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001000165939331"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1234342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc38506b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions = model.predict(test_features)\n",
    "\n",
    "# Convert raw predictions to binary labels using a threshold (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "predicted_labels = (raw_predictions > threshold).astype(int)\n",
    "raw_predictions = [array[0] for array in raw_predictions]\n",
    "\n",
    "\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d24c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_predicted_labels = [array[0] for array in predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "531526c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"predicted_labels\": processed_predicted_labels\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7649d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"CNN_run3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4619967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931775212287903"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96c14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa03373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2795e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d133851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c04ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2cba5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e865e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b754af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2950ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574158f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c6324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ce1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Function to create a Keras model\n",
    "def create_model(learning_rate=0.001, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_dim=train_features.shape[1]))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'dropout_rate': [0.0, 0.2, 0.4]\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=3), verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_result = grid.fit(train_features, train_labels)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Accuracy: {:.2f}%\".format(grid_result.best_score_ * 100))\n",
    "\n",
    "# Access the best model from the grid search\n",
    "best_model = grid_result.best_estimator_.model\"\"\";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
