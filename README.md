# Multimodal-Hate-Speech-Detection

In the rapidly evolving landscape of social media, platforms such as X (formerly Twitter) have emerged as powerful mediums for global expression, allowing individuals a platform to share thoughts, ideas, and experiences. However, this unprecedented connectivity has brought to light a concerning challenge - the amplification of hateful speech and offensive content. Hate speech can be defined as any communication using offensive language to target individuals or groups based on identity factors such as religion, ethnicity, nationality, race, color, gender, or other characteristics, poses a significant threat to online safety and well-being. The prevalence of hate speech on social media platforms can have lots of detrimental effects. It contributes significantly to the creation of division, fear, and societal tension, fostering discrimination and marginalization. Beyond its societal impact, hate speech inflicts psychological harm, causing emotional distress and fear among targeted individuals and communities. Moreover, the surge in hate speech raises profound legal and ethical questions, touching upon issues of free speech, censorship, and discrimination. In response to this critical issue, our project aims to develop a machine learning model that can effectively differentiate between hateful and non-hateful tweets. This model will leverage both textual and image data associated with each tweet, employing a multimodal approach to comprehensively analyze and classify content. By utilizing the power of artificial intelligence in conjunction with both text and image features, our objective is to provide a robust solution for combating the spread of hate speech on social media platforms.  
